Start Training ...................................

          Initializing TSN with base model: BNInception.
          TSN Configurations:
              input_modality:     RGBDiff
              num_segments:       3
              new_length:         5
              consensus_module:   avg
              dropout_ratio:      0.8
               
Load and modify the standard model FC output layer
Dropout Layer added and The modified linear layer is : Linear(in_features=1024, out_features=101, bias=True)
Done. Loading and Modifying 
 ---------------------------------------------------
Converting the ImageNet model to RGBDiff model
The modified 1st layer is Conv2d(15, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
Done. RGBDiff model is ready.
Loading checkpoint '_rgbdiff_checkpoint.pth.tar'
Loaded checkpoint 'False' epoch 65
---------------------------------------------------
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 1 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 69 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 69 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
---------------------------------------------------
Epoch: [65][0/150], lr: 0.00100	Time 593.454 (593.454)	Data 379.293 (379.293)	Loss 0.1282 (0.1282)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [65][20/150], lr: 0.00100	Time 65.238 (32.698)	Data 62.259 (21.027)	Loss 0.0580 (0.1145)	Acc@1 98.438 (96.429)	Acc@5 100.000 (99.702)
Epoch: [65][40/150], lr: 0.00100	Time 1.297 (18.930)	Data 0.000 (12.187)	Loss 0.1336 (0.1169)	Acc@1 96.875 (96.456)	Acc@5 98.438 (99.543)
Epoch: [65][60/150], lr: 0.00100	Time 2.913 (13.736)	Data 0.001 (8.655)	Loss 0.2251 (0.1178)	Acc@1 93.750 (96.183)	Acc@5 100.000 (99.667)
Epoch: [65][80/150], lr: 0.00100	Time 1.466 (10.840)	Data 0.001 (6.588)	Loss 0.0192 (0.1282)	Acc@1 100.000 (95.795)	Acc@5 100.000 (99.633)
Epoch: [65][100/150], lr: 0.00100	Time 1.429 (10.023)	Data 0.000 (6.267)	Loss 0.1475 (0.1336)	Acc@1 93.750 (95.746)	Acc@5 100.000 (99.644)
Epoch: [65][120/150], lr: 0.00100	Time 2.687 (8.710)	Data 0.000 (5.278)	Loss 0.1088 (0.1348)	Acc@1 98.438 (95.713)	Acc@5 100.000 (99.677)
Epoch: [65][140/150], lr: 0.00100	Time 1.339 (7.875)	Data 0.000 (4.703)	Loss 0.0865 (0.1356)	Acc@1 96.875 (95.734)	Acc@5 100.000 (99.679)
Epoch: [66][0/150], lr: 0.00100	Time 187.656 (187.656)	Data 179.677 (179.677)	Loss 0.2413 (0.2413)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)
Epoch: [66][20/150], lr: 0.00100	Time 1.704 (18.655)	Data 0.001 (15.575)	Loss 0.1471 (0.1505)	Acc@1 93.750 (95.387)	Acc@5 100.000 (99.702)
Epoch: [66][40/150], lr: 0.00100	Time 1.368 (13.068)	Data 0.000 (10.584)	Loss 0.1300 (0.1278)	Acc@1 95.312 (95.922)	Acc@5 100.000 (99.848)
Epoch: [66][60/150], lr: 0.00100	Time 7.567 (15.103)	Data 0.003 (12.622)	Loss 0.0158 (0.1308)	Acc@1 100.000 (96.132)	Acc@5 100.000 (99.872)
Epoch: [66][80/150], lr: 0.00100	Time 148.079 (18.361)	Data 145.962 (15.803)	Loss 0.2121 (0.1317)	Acc@1 95.312 (96.046)	Acc@5 100.000 (99.846)
Epoch: [66][100/150], lr: 0.00100	Time 1.924 (16.943)	Data 0.002 (14.485)	Loss 0.1716 (0.1400)	Acc@1 90.625 (95.777)	Acc@5 100.000 (99.768)
Epoch: [66][120/150], lr: 0.00100	Time 1.489 (17.255)	Data 0.000 (14.858)	Loss 0.1562 (0.1347)	Acc@1 95.312 (95.894)	Acc@5 100.000 (99.806)
Epoch: [66][140/150], lr: 0.00100	Time 1.350 (15.731)	Data 0.000 (13.405)	Loss 0.1125 (0.1342)	Acc@1 95.312 (95.900)	Acc@5 100.000 (99.801)
Epoch: [67][0/150], lr: 0.00100	Time 336.462 (336.462)	Data 326.069 (326.069)	Loss 0.2764 (0.2764)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [67][20/150], lr: 0.00100	Time 1.508 (26.178)	Data 0.001 (22.141)	Loss 0.1338 (0.1131)	Acc@1 95.312 (96.131)	Acc@5 100.000 (99.851)
Epoch: [67][40/150], lr: 0.00100	Time 4.368 (17.754)	Data 0.003 (13.308)	Loss 0.0700 (0.1205)	Acc@1 96.875 (96.113)	Acc@5 100.000 (99.809)
Epoch: [67][60/150], lr: 0.00100	Time 2.228 (16.152)	Data 0.001 (11.967)	Loss 0.1507 (0.1268)	Acc@1 96.875 (96.055)	Acc@5 100.000 (99.795)
Epoch: [67][80/150], lr: 0.00100	Time 47.080 (16.788)	Data 43.864 (11.362)	Loss 0.0709 (0.1286)	Acc@1 98.438 (96.103)	Acc@5 100.000 (99.749)
Epoch: [67][100/150], lr: 0.00100	Time 1.453 (15.619)	Data 0.000 (10.546)	Loss 0.1037 (0.1318)	Acc@1 95.312 (96.024)	Acc@5 100.000 (99.752)
Epoch: [67][120/150], lr: 0.00100	Time 1.811 (15.239)	Data 0.001 (10.054)	Loss 0.1267 (0.1367)	Acc@1 96.875 (95.855)	Acc@5 100.000 (99.716)
Epoch: [67][140/150], lr: 0.00100	Time 1.352 (14.190)	Data 0.000 (8.794)	Loss 0.1616 (0.1408)	Acc@1 93.750 (95.656)	Acc@5 98.438 (99.690)
Epoch: [68][0/150], lr: 0.00100	Time 229.173 (229.173)	Data 219.847 (219.847)	Loss 0.0327 (0.0327)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [68][20/150], lr: 0.00100	Time 44.237 (20.847)	Data 0.004 (15.418)	Loss 0.0576 (0.1101)	Acc@1 100.000 (96.131)	Acc@5 100.000 (99.926)
Epoch: [68][40/150], lr: 0.00100	Time 19.309 (21.075)	Data 12.547 (14.345)	Loss 0.0873 (0.0991)	Acc@1 95.312 (96.532)	Acc@5 100.000 (99.886)
Epoch: [68][60/150], lr: 0.00100	Time 3.349 (25.047)	Data 0.001 (14.001)	Loss 0.1126 (0.1102)	Acc@1 96.875 (96.311)	Acc@5 100.000 (99.821)
Epoch: [68][80/150], lr: 0.00100	Time 1.510 (21.376)	Data 0.001 (12.243)	Loss 0.0907 (0.1187)	Acc@1 95.312 (96.181)	Acc@5 100.000 (99.807)
Epoch: [68][100/150], lr: 0.00100	Time 1.366 (24.545)	Data 0.000 (16.771)	Loss 0.0774 (0.1209)	Acc@1 96.875 (96.194)	Acc@5 100.000 (99.799)
Epoch: [68][120/150], lr: 0.00100	Time 1.414 (20.731)	Data 0.000 (14.000)	Loss 0.2574 (0.1239)	Acc@1 92.188 (96.178)	Acc@5 98.438 (99.755)
Epoch: [68][140/150], lr: 0.00100	Time 1.304 (19.616)	Data 0.000 (13.626)	Loss 0.1367 (0.1280)	Acc@1 95.312 (96.022)	Acc@5 100.000 (99.767)
Epoch: [69][0/150], lr: 0.00100	Time 201.718 (201.718)	Data 196.135 (196.135)	Loss 0.1933 (0.1933)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [69][20/150], lr: 0.00100	Time 1.419 (21.381)	Data 0.000 (18.782)	Loss 0.0396 (0.0992)	Acc@1 100.000 (96.503)	Acc@5 100.000 (99.926)
Epoch: [69][40/150], lr: 0.00100	Time 2.095 (29.201)	Data 0.003 (26.675)	Loss 0.1549 (0.1241)	Acc@1 98.438 (96.265)	Acc@5 98.438 (99.809)
Epoch: [69][60/150], lr: 0.00100	Time 1.399 (23.641)	Data 0.001 (21.269)	Loss 0.0968 (0.1284)	Acc@1 98.438 (96.081)	Acc@5 100.000 (99.821)
Epoch: [69][80/150], lr: 0.00100	Time 1.662 (20.686)	Data 0.003 (18.406)	Loss 0.0450 (0.1267)	Acc@1 98.438 (96.277)	Acc@5 100.000 (99.788)
Epoch: [69][100/150], lr: 0.00100	Time 5.200 (21.450)	Data 0.025 (18.836)	Loss 0.0427 (0.1286)	Acc@1 98.438 (96.210)	Acc@5 100.000 (99.783)
Epoch: [69][120/150], lr: 0.00100	Time 6.850 (19.690)	Data 0.003 (17.062)	Loss 0.3661 (0.1248)	Acc@1 95.312 (96.346)	Acc@5 98.438 (99.793)
Epoch: [69][140/150], lr: 0.00100	Time 1.309 (18.378)	Data 0.000 (15.164)	Loss 0.0746 (0.1259)	Acc@1 98.438 (96.210)	Acc@5 100.000 (99.778)
Test: [0/60]	Time 226.844 (226.844)	Loss 1.5579 (1.5579)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
Test: [20/60]	Time 0.596 (16.906)	Loss 4.3178 (1.7692)	Acc@1 43.750 (65.253)	Acc@5 64.062 (87.128)
Test: [40/60]	Time 0.557 (15.312)	Loss 1.2615 (1.6306)	Acc@1 70.312 (68.255)	Acc@5 92.188 (89.024)
 * Acc@1 68.834 Acc@5 89.559 Loss 1.57262
Epoch: [70][0/150], lr: 0.00100	Time 201.819 (201.819)	Data 193.866 (193.866)	Loss 0.1687 (0.1687)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [70][20/150], lr: 0.00100	Time 2.239 (18.872)	Data 0.003 (15.853)	Loss 0.1140 (0.1739)	Acc@1 98.438 (95.312)	Acc@5 100.000 (99.330)
Epoch: [70][40/150], lr: 0.00100	Time 1.307 (21.667)	Data 0.000 (18.754)	Loss 0.2613 (0.1602)	Acc@1 90.625 (95.503)	Acc@5 100.000 (99.466)
Epoch: [70][60/150], lr: 0.00100	Time 1.378 (16.387)	Data 0.001 (13.643)	Loss 0.2184 (0.1508)	Acc@1 93.750 (95.671)	Acc@5 100.000 (99.565)
Epoch: [70][80/150], lr: 0.00100	Time 59.409 (18.064)	Data 54.745 (15.435)	Loss 0.2795 (0.1487)	Acc@1 95.312 (95.660)	Acc@5 98.438 (99.556)
Epoch: [70][100/150], lr: 0.00100	Time 1.347 (18.003)	Data 0.003 (15.417)	Loss 0.0312 (0.1439)	Acc@1 100.000 (95.761)	Acc@5 100.000 (99.613)
Epoch: [70][120/150], lr: 0.00100	Time 11.010 (19.542)	Data 0.018 (16.669)	Loss 0.1536 (0.1410)	Acc@1 95.312 (95.894)	Acc@5 98.438 (99.626)
Epoch: [70][140/150], lr: 0.00100	Time 1.346 (17.966)	Data 0.000 (15.282)	Loss 0.0965 (0.1376)	Acc@1 96.875 (96.022)	Acc@5 100.000 (99.634)
Epoch: [71][0/150], lr: 0.00100	Time 245.544 (245.544)	Data 238.586 (238.586)	Loss 0.0738 (0.0738)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [71][20/150], lr: 0.00100	Time 1.841 (26.899)	Data 0.003 (24.263)	Loss 0.1000 (0.1296)	Acc@1 96.875 (95.610)	Acc@5 100.000 (99.702)
Epoch: [71][40/150], lr: 0.00100	Time 1.734 (22.560)	Data 0.001 (19.800)	Loss 0.0666 (0.1268)	Acc@1 98.438 (96.113)	Acc@5 100.000 (99.581)
Epoch: [71][60/150], lr: 0.00100	Time 1.417 (19.325)	Data 0.001 (16.828)	Loss 0.0574 (0.1278)	Acc@1 98.438 (96.107)	Acc@5 100.000 (99.590)
Epoch: [71][80/150], lr: 0.00100	Time 1.467 (22.215)	Data 0.000 (19.895)	Loss 0.1478 (0.1290)	Acc@1 95.312 (96.007)	Acc@5 100.000 (99.595)
Epoch: [71][100/150], lr: 0.00100	Time 601.099 (53.155)	Data 598.812 (50.948)	Loss 0.1514 (0.1348)	Acc@1 96.875 (95.792)	Acc@5 100.000 (99.613)
Epoch: [71][120/150], lr: 0.00100	Time 1.594 (175.647)	Data 0.000 (173.448)	Loss 0.1619 (0.1328)	Acc@1 95.312 (95.842)	Acc@5 100.000 (99.638)
Epoch: [71][140/150], lr: 0.00100	Time 1.659 (230.948)	Data 0.000 (228.751)	Loss 0.1254 (0.1373)	Acc@1 93.750 (95.700)	Acc@5 100.000 (99.634)
slurmstepd: error: *** JOB 223818 ON comp001 CANCELLED AT 2019-02-22T14:45:33 DUE TO TIME LIMIT ***

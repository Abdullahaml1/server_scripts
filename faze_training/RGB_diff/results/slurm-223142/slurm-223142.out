Start Training ...................................

          Initializing TSN with base model: BNInception.
          TSN Configurations:
              input_modality:     RGBDiff
              num_segments:       7
              new_length:         5
              consensus_module:   avg
              dropout_ratio:      0.8
               
Load and modify the standard model FC output layer
Dropout Layer added and The modified linear layer is : Linear(in_features=1024, out_features=101, bias=True)
Done. Loading and Modifying 
 ---------------------------------------------------
Converting the ImageNet model to RGBDiff model
The modified 1st layer is Conv2d(15, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
Done. RGBDiff model is ready.
---------------------------------------------------
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 1 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 69 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 69 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
---------------------------------------------------
Epoch: [0][0/150], lr: 0.00100	Time 85.470 (85.470)	Data 63.351 (63.351)	Loss 4.6200 (4.6200)	Acc@1 0.000 (0.000)	Acc@5 0.000 (0.000)
Epoch: [0][20/150], lr: 0.00100	Time 54.695 (31.116)	Data 51.257 (27.000)	Loss 4.5138 (4.5601)	Acc@1 3.125 (2.455)	Acc@5 14.062 (8.557)
Epoch: [0][40/150], lr: 0.00100	Time 51.425 (29.738)	Data 48.146 (26.050)	Loss 3.9929 (4.3823)	Acc@1 7.812 (5.488)	Acc@5 34.375 (16.120)
Epoch: [0][60/150], lr: 0.00100	Time 51.840 (28.890)	Data 47.755 (25.360)	Loss 3.6201 (4.1569)	Acc@1 21.875 (8.837)	Acc@5 39.062 (22.823)
Epoch: [0][80/150], lr: 0.00100	Time 52.130 (28.435)	Data 48.700 (24.969)	Loss 3.1608 (3.8987)	Acc@1 17.188 (11.941)	Acc@5 48.438 (30.112)
Epoch: [0][100/150], lr: 0.00100	Time 45.154 (27.749)	Data 41.896 (24.343)	Loss 2.6529 (3.6800)	Acc@1 32.812 (15.579)	Acc@5 64.062 (35.984)
Epoch: [0][120/150], lr: 0.00100	Time 42.069 (27.092)	Data 38.486 (23.719)	Loss 2.4328 (3.4881)	Acc@1 31.250 (19.215)	Acc@5 67.188 (40.999)
Epoch: [0][140/150], lr: 0.00100	Time 34.275 (26.512)	Data 30.780 (23.168)	Loss 2.0149 (3.3082)	Acc@1 48.438 (22.374)	Acc@5 73.438 (45.833)
Epoch: [1][0/150], lr: 0.00100	Time 55.506 (55.506)	Data 51.230 (51.230)	Loss 1.9502 (1.9502)	Acc@1 43.750 (43.750)	Acc@5 79.688 (79.688)
Epoch: [1][20/150], lr: 0.00100	Time 41.767 (24.371)	Data 38.532 (21.081)	Loss 1.8678 (2.0353)	Acc@1 42.188 (46.131)	Acc@5 87.500 (77.604)
Epoch: [1][40/150], lr: 0.00100	Time 41.675 (23.485)	Data 38.480 (20.255)	Loss 1.7820 (1.9447)	Acc@1 48.438 (48.056)	Acc@5 84.375 (78.887)
Epoch: [1][60/150], lr: 0.00100	Time 44.094 (23.704)	Data 40.797 (20.490)	Loss 1.6999 (1.8336)	Acc@1 53.125 (50.487)	Acc@5 79.688 (81.019)
Epoch: [1][80/150], lr: 0.00100	Time 44.598 (23.720)	Data 41.346 (20.519)	Loss 1.0483 (1.7688)	Acc@1 71.875 (52.411)	Acc@5 89.062 (81.925)
Epoch: [1][100/150], lr: 0.00100	Time 42.703 (23.663)	Data 39.471 (20.467)	Loss 1.5798 (1.7312)	Acc@1 53.125 (53.140)	Acc@5 84.375 (82.488)
Epoch: [1][120/150], lr: 0.00100	Time 40.721 (23.421)	Data 37.513 (20.233)	Loss 1.4659 (1.6991)	Acc@1 62.500 (53.848)	Acc@5 87.500 (83.032)
Epoch: [1][140/150], lr: 0.00100	Time 40.837 (23.200)	Data 37.645 (20.015)	Loss 1.4535 (1.6393)	Acc@1 60.938 (55.430)	Acc@5 87.500 (83.910)
Epoch: [2][0/150], lr: 0.00100	Time 47.253 (47.253)	Data 43.757 (43.757)	Loss 1.2279 (1.2279)	Acc@1 60.938 (60.938)	Acc@5 90.625 (90.625)
Epoch: [2][20/150], lr: 0.00100	Time 37.382 (21.855)	Data 34.186 (18.623)	Loss 1.3519 (1.1902)	Acc@1 60.938 (66.071)	Acc@5 92.188 (90.923)
Epoch: [2][40/150], lr: 0.00100	Time 35.947 (21.313)	Data 32.496 (18.122)	Loss 1.2922 (1.2008)	Acc@1 68.750 (65.968)	Acc@5 89.062 (90.358)
Epoch: [2][60/150], lr: 0.00100	Time 34.816 (21.149)	Data 31.635 (17.978)	Loss 1.2848 (1.2136)	Acc@1 60.938 (65.369)	Acc@5 90.625 (90.497)
Epoch: [2][80/150], lr: 0.00100	Time 37.921 (21.073)	Data 34.599 (17.897)	Loss 1.3310 (1.1842)	Acc@1 68.750 (66.107)	Acc@5 87.500 (90.741)
Epoch: [2][100/150], lr: 0.00100	Time 37.524 (20.953)	Data 34.176 (17.766)	Loss 0.9105 (1.1626)	Acc@1 81.250 (66.847)	Acc@5 92.188 (91.074)
Epoch: [2][120/150], lr: 0.00100	Time 38.005 (20.903)	Data 34.857 (17.705)	Loss 1.1882 (1.1331)	Acc@1 64.062 (67.575)	Acc@5 89.062 (91.503)
Epoch: [2][140/150], lr: 0.00100	Time 36.837 (20.831)	Data 33.315 (17.629)	Loss 0.9472 (1.1092)	Acc@1 68.750 (68.229)	Acc@5 92.188 (91.811)
Epoch: [3][0/150], lr: 0.00100	Time 46.404 (46.404)	Data 42.907 (42.907)	Loss 1.0068 (1.0068)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Epoch: [3][20/150], lr: 0.00100	Time 35.787 (20.820)	Data 32.651 (17.670)	Loss 0.9288 (0.9908)	Acc@1 75.000 (71.726)	Acc@5 96.875 (93.006)
Epoch: [3][40/150], lr: 0.00100	Time 36.506 (20.219)	Data 33.451 (17.086)	Loss 0.9298 (0.9541)	Acc@1 73.438 (71.837)	Acc@5 96.875 (93.293)
Epoch: [3][60/150], lr: 0.00100	Time 35.390 (19.950)	Data 32.331 (16.806)	Loss 0.9342 (0.9405)	Acc@1 70.312 (72.976)	Acc@5 89.062 (93.391)
Epoch: [3][80/150], lr: 0.00100	Time 35.663 (19.910)	Data 32.529 (16.772)	Loss 0.9262 (0.9298)	Acc@1 70.312 (73.225)	Acc@5 93.750 (93.634)
Epoch: [3][100/150], lr: 0.00100	Time 36.527 (19.915)	Data 33.455 (16.773)	Loss 0.7012 (0.9152)	Acc@1 82.812 (73.360)	Acc@5 95.312 (93.812)
Epoch: [3][120/150], lr: 0.00100	Time 36.951 (19.925)	Data 33.804 (16.791)	Loss 0.7237 (0.9118)	Acc@1 73.438 (73.735)	Acc@5 95.312 (93.892)
Epoch: [3][140/150], lr: 0.00100	Time 36.859 (19.945)	Data 33.684 (16.811)	Loss 0.5275 (0.9033)	Acc@1 82.812 (73.814)	Acc@5 98.438 (94.016)
Epoch: [4][0/150], lr: 0.00100	Time 45.337 (45.337)	Data 41.802 (41.802)	Loss 0.9178 (0.9178)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [4][20/150], lr: 0.00100	Time 34.731 (20.374)	Data 31.523 (17.188)	Loss 0.6109 (0.7550)	Acc@1 79.688 (77.083)	Acc@5 96.875 (96.205)
Epoch: [4][40/150], lr: 0.00100	Time 36.205 (19.891)	Data 32.971 (16.717)	Loss 0.4940 (0.7203)	Acc@1 81.250 (78.773)	Acc@5 98.438 (96.227)
Epoch: [4][60/150], lr: 0.00100	Time 36.990 (19.712)	Data 33.665 (16.541)	Loss 0.7094 (0.7311)	Acc@1 78.125 (79.022)	Acc@5 95.312 (96.183)
Epoch: [4][80/150], lr: 0.00100	Time 33.142 (19.799)	Data 30.006 (16.625)	Loss 0.8410 (0.7129)	Acc@1 71.875 (79.225)	Acc@5 96.875 (96.354)
Epoch: [4][100/150], lr: 0.00100	Time 31.946 (19.780)	Data 28.780 (16.598)	Loss 0.6853 (0.7099)	Acc@1 81.250 (79.192)	Acc@5 96.875 (96.442)
Epoch: [4][120/150], lr: 0.00100	Time 33.629 (19.818)	Data 30.415 (16.636)	Loss 0.7743 (0.7131)	Acc@1 75.000 (79.068)	Acc@5 96.875 (96.358)
Epoch: [4][140/150], lr: 0.00100	Time 34.909 (19.898)	Data 31.764 (16.715)	Loss 0.6676 (0.7247)	Acc@1 79.688 (78.801)	Acc@5 95.312 (96.188)
Test: [0/60]	Time 50.885 (50.885)	Loss 1.2515 (1.2515)	Acc@1 60.938 (60.938)	Acc@5 93.750 (93.750)
Test: [20/60]	Time 44.202 (23.607)	Loss 3.2476 (1.4826)	Acc@1 32.812 (63.318)	Acc@5 64.062 (86.533)
Test: [40/60]	Time 51.185 (23.636)	Loss 1.0905 (1.3613)	Acc@1 70.312 (65.053)	Acc@5 90.625 (88.529)
 * Acc@1 63.600 Acc@5 87.365 Loss 1.46154
Epoch: [5][0/150], lr: 0.00100	Time 50.353 (50.353)	Data 46.344 (46.344)	Loss 0.6608 (0.6608)	Acc@1 79.688 (79.688)	Acc@5 96.875 (96.875)
Epoch: [5][20/150], lr: 0.00100	Time 38.070 (22.761)	Data 34.637 (19.421)	Loss 0.6160 (0.7091)	Acc@1 82.812 (79.167)	Acc@5 95.312 (96.131)
Epoch: [5][40/150], lr: 0.00100	Time 38.045 (21.930)	Data 34.993 (18.669)	Loss 0.5837 (0.7005)	Acc@1 82.812 (80.450)	Acc@5 96.875 (95.960)
Epoch: [5][60/150], lr: 0.00100	Time 39.228 (21.786)	Data 35.626 (18.540)	Loss 0.4735 (0.6439)	Acc@1 87.500 (81.660)	Acc@5 96.875 (96.644)
Epoch: [5][80/150], lr: 0.00100	Time 38.708 (21.672)	Data 35.238 (18.446)	Loss 0.5366 (0.6308)	Acc@1 85.938 (81.848)	Acc@5 98.438 (96.586)
Epoch: [5][100/150], lr: 0.00100	Time 37.784 (21.485)	Data 34.677 (18.262)	Loss 0.7349 (0.6349)	Acc@1 82.812 (81.745)	Acc@5 96.875 (96.627)
Epoch: [5][120/150], lr: 0.00100	Time 38.191 (21.388)	Data 34.801 (18.171)	Loss 0.3974 (0.6263)	Acc@1 85.938 (82.064)	Acc@5 95.312 (96.746)
Epoch: [5][140/150], lr: 0.00100	Time 38.659 (21.330)	Data 35.599 (18.121)	Loss 0.5874 (0.6155)	Acc@1 82.812 (82.203)	Acc@5 95.312 (96.820)
Epoch: [6][0/150], lr: 0.00100	Time 45.945 (45.945)	Data 42.297 (42.297)	Loss 0.4593 (0.4593)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [6][20/150], lr: 0.00100	Time 36.396 (21.197)	Data 33.189 (18.017)	Loss 0.5162 (0.5912)	Acc@1 87.500 (82.440)	Acc@5 98.438 (97.545)
Epoch: [6][40/150], lr: 0.00100	Time 36.524 (20.442)	Data 33.078 (17.217)	Loss 0.4747 (0.5598)	Acc@1 85.938 (83.460)	Acc@5 98.438 (97.675)
Epoch: [6][60/150], lr: 0.00100	Time 36.106 (20.217)	Data 32.818 (17.026)	Loss 0.3978 (0.5519)	Acc@1 89.062 (83.581)	Acc@5 98.438 (97.567)
Epoch: [6][80/150], lr: 0.00100	Time 37.506 (20.124)	Data 33.860 (16.934)	Loss 0.4389 (0.5361)	Acc@1 87.500 (84.182)	Acc@5 95.312 (97.743)
Epoch: [6][100/150], lr: 0.00100	Time 36.158 (20.013)	Data 33.001 (16.824)	Loss 0.5796 (0.5313)	Acc@1 82.812 (84.174)	Acc@5 95.312 (97.741)
Epoch: [6][120/150], lr: 0.00100	Time 36.267 (19.920)	Data 33.014 (16.737)	Loss 0.4140 (0.5310)	Acc@1 85.938 (84.104)	Acc@5 100.000 (97.843)
Epoch: [6][140/150], lr: 0.00100	Time 36.179 (19.851)	Data 32.603 (16.666)	Loss 0.7243 (0.5361)	Acc@1 73.438 (84.031)	Acc@5 96.875 (97.762)
Epoch: [7][0/150], lr: 0.00100	Time 45.575 (45.575)	Data 42.310 (42.310)	Loss 0.7352 (0.7352)	Acc@1 82.812 (82.812)	Acc@5 96.875 (96.875)
Epoch: [7][20/150], lr: 0.00100	Time 34.966 (20.664)	Data 31.989 (17.529)	Loss 0.5738 (0.6165)	Acc@1 81.250 (82.217)	Acc@5 98.438 (96.875)
Epoch: [7][40/150], lr: 0.00100	Time 36.131 (20.140)	Data 33.029 (16.990)	Loss 0.5136 (0.6071)	Acc@1 81.250 (82.660)	Acc@5 98.438 (97.104)
Epoch: [7][60/150], lr: 0.00100	Time 37.099 (19.949)	Data 34.011 (16.806)	Loss 0.4138 (0.5584)	Acc@1 87.500 (83.811)	Acc@5 98.438 (97.310)
Epoch: [7][80/150], lr: 0.00100	Time 36.691 (20.003)	Data 33.588 (16.860)	Loss 0.4358 (0.5295)	Acc@1 85.938 (84.394)	Acc@5 100.000 (97.531)
Epoch: [7][100/150], lr: 0.00100	Time 36.261 (19.977)	Data 33.220 (16.841)	Loss 0.6306 (0.5177)	Acc@1 82.812 (84.855)	Acc@5 95.312 (97.556)
Epoch: [7][120/150], lr: 0.00100	Time 36.300 (19.948)	Data 32.944 (16.809)	Loss 0.4436 (0.5045)	Acc@1 85.938 (85.111)	Acc@5 98.438 (97.701)
Epoch: [7][140/150], lr: 0.00100	Time 36.848 (19.900)	Data 33.720 (16.762)	Loss 0.4401 (0.4902)	Acc@1 87.500 (85.450)	Acc@5 100.000 (97.762)
Epoch: [8][0/150], lr: 0.00100	Time 46.902 (46.902)	Data 43.521 (43.521)	Loss 0.2874 (0.2874)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
Epoch: [8][20/150], lr: 0.00100	Time 33.904 (20.314)	Data 30.181 (16.997)	Loss 0.4053 (0.4234)	Acc@1 87.500 (86.607)	Acc@5 98.438 (99.107)
Epoch: [8][40/150], lr: 0.00100	Time 34.365 (19.808)	Data 30.809 (16.512)	Loss 0.4641 (0.3853)	Acc@1 85.938 (87.919)	Acc@5 96.875 (98.780)
Epoch: [8][60/150], lr: 0.00100	Time 35.989 (19.692)	Data 32.262 (16.412)	Loss 0.3254 (0.4001)	Acc@1 85.938 (87.602)	Acc@5 100.000 (98.770)
Epoch: [8][80/150], lr: 0.00100	Time 34.150 (19.619)	Data 30.584 (16.354)	Loss 0.1320 (0.3973)	Acc@1 95.312 (87.809)	Acc@5 100.000 (98.669)
Epoch: [8][100/150], lr: 0.00100	Time 35.827 (19.577)	Data 31.975 (16.322)	Loss 0.2264 (0.3989)	Acc@1 96.875 (87.933)	Acc@5 100.000 (98.561)
Epoch: [8][120/150], lr: 0.00100	Time 35.640 (19.506)	Data 32.468 (16.261)	Loss 0.4137 (0.3980)	Acc@1 89.062 (87.926)	Acc@5 96.875 (98.541)
Epoch: [8][140/150], lr: 0.00100	Time 34.772 (19.478)	Data 31.443 (16.245)	Loss 0.5571 (0.4033)	Acc@1 82.812 (87.711)	Acc@5 96.875 (98.504)
Epoch: [9][0/150], lr: 0.00100	Time 44.796 (44.796)	Data 41.453 (41.453)	Loss 0.5055 (0.5055)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [9][20/150], lr: 0.00100	Time 34.359 (19.796)	Data 30.841 (16.584)	Loss 0.5654 (0.4794)	Acc@1 82.812 (86.384)	Acc@5 100.000 (98.363)
Epoch: [9][40/150], lr: 0.00100	Time 34.548 (19.409)	Data 31.507 (16.220)	Loss 0.4997 (0.4218)	Acc@1 84.375 (87.919)	Acc@5 98.438 (98.514)
Epoch: [9][60/150], lr: 0.00100	Time 35.550 (19.173)	Data 32.016 (15.961)	Loss 0.4949 (0.3980)	Acc@1 85.938 (88.012)	Acc@5 95.312 (98.540)
Epoch: [9][80/150], lr: 0.00100	Time 34.598 (19.052)	Data 31.065 (15.841)	Loss 0.3806 (0.3884)	Acc@1 87.500 (88.349)	Acc@5 100.000 (98.669)
Epoch: [9][100/150], lr: 0.00100	Time 32.267 (19.020)	Data 29.116 (15.819)	Loss 0.2911 (0.3790)	Acc@1 93.750 (88.428)	Acc@5 100.000 (98.762)
Epoch: [9][120/150], lr: 0.00100	Time 34.413 (18.995)	Data 30.985 (15.796)	Loss 0.5919 (0.3771)	Acc@1 87.500 (88.714)	Acc@5 98.438 (98.786)
Epoch: [9][140/150], lr: 0.00100	Time 31.865 (18.983)	Data 28.760 (15.792)	Loss 0.4292 (0.3743)	Acc@1 82.812 (88.597)	Acc@5 98.438 (98.748)
Test: [0/60]	Time 44.151 (44.151)	Loss 0.2888 (0.2888)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Test: [20/60]	Time 37.562 (19.868)	Loss 2.7641 (1.1674)	Acc@1 48.438 (70.089)	Acc@5 67.188 (91.146)
Test: [40/60]	Time 35.857 (19.267)	Loss 0.9794 (1.1553)	Acc@1 82.812 (70.960)	Acc@5 89.062 (90.358)
 * Acc@1 70.896 Acc@5 91.039 Loss 1.12166
Epoch: [10][0/150], lr: 0.00100	Time 44.515 (44.515)	Data 41.171 (41.171)	Loss 0.3317 (0.3317)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
Epoch: [10][20/150], lr: 0.00100	Time 35.264 (20.677)	Data 32.084 (17.467)	Loss 0.6037 (0.3844)	Acc@1 84.375 (88.542)	Acc@5 98.438 (98.363)
Epoch: [10][40/150], lr: 0.00100	Time 35.596 (20.042)	Data 32.088 (16.826)	Loss 0.2983 (0.3820)	Acc@1 87.500 (88.720)	Acc@5 100.000 (98.552)
Epoch: [10][60/150], lr: 0.00100	Time 34.496 (19.852)	Data 31.317 (16.644)	Loss 0.1482 (0.3834)	Acc@1 96.875 (88.499)	Acc@5 100.000 (98.642)
Epoch: [10][80/150], lr: 0.00100	Time 33.193 (19.741)	Data 29.817 (16.547)	Loss 0.2454 (0.3685)	Acc@1 96.875 (89.005)	Acc@5 100.000 (98.630)
Epoch: [10][100/150], lr: 0.00100	Time 32.500 (19.655)	Data 29.160 (16.467)	Loss 0.3259 (0.3567)	Acc@1 90.625 (89.186)	Acc@5 98.438 (98.762)
Epoch: [10][120/150], lr: 0.00100	Time 34.367 (19.620)	Data 31.174 (16.436)	Loss 0.3441 (0.3560)	Acc@1 89.062 (89.308)	Acc@5 100.000 (98.773)
Epoch: [10][140/150], lr: 0.00100	Time 31.250 (19.556)	Data 28.100 (16.376)	Loss 0.2156 (0.3529)	Acc@1 92.188 (89.251)	Acc@5 100.000 (98.803)
Epoch: [11][0/150], lr: 0.00100	Time 45.981 (45.981)	Data 42.785 (42.785)	Loss 0.4298 (0.4298)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [11][20/150], lr: 0.00100	Time 34.342 (19.959)	Data 31.284 (16.821)	Loss 0.2647 (0.3267)	Acc@1 89.062 (89.583)	Acc@5 98.438 (98.958)
Epoch: [11][40/150], lr: 0.00100	Time 34.748 (19.428)	Data 31.643 (16.250)	Loss 0.4047 (0.3231)	Acc@1 87.500 (89.710)	Acc@5 100.000 (98.933)
Epoch: [11][60/150], lr: 0.00100	Time 35.213 (19.237)	Data 32.039 (16.078)	Loss 0.2068 (0.3179)	Acc@1 95.312 (90.036)	Acc@5 98.438 (98.950)
Epoch: [11][80/150], lr: 0.00100	Time 36.039 (19.122)	Data 32.966 (15.954)	Loss 0.4041 (0.3133)	Acc@1 89.062 (90.278)	Acc@5 98.438 (99.035)
Epoch: [11][100/150], lr: 0.00100	Time 34.357 (19.050)	Data 31.111 (15.878)	Loss 0.3121 (0.3136)	Acc@1 87.500 (90.238)	Acc@5 96.875 (99.025)
Epoch: [11][120/150], lr: 0.00100	Time 35.297 (19.032)	Data 32.256 (15.862)	Loss 0.2101 (0.3133)	Acc@1 90.625 (90.199)	Acc@5 100.000 (99.032)
Epoch: [11][140/150], lr: 0.00100	Time 33.925 (19.017)	Data 30.778 (15.856)	Loss 0.2536 (0.3138)	Acc@1 92.188 (90.160)	Acc@5 100.000 (99.080)
Epoch: [12][0/150], lr: 0.00100	Time 45.052 (45.052)	Data 41.396 (41.396)	Loss 0.2500 (0.2500)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [12][20/150], lr: 0.00100	Time 33.247 (19.686)	Data 29.969 (16.410)	Loss 0.3660 (0.2845)	Acc@1 89.062 (91.071)	Acc@5 96.875 (99.405)
Epoch: [12][40/150], lr: 0.00100	Time 35.091 (19.124)	Data 31.719 (15.881)	Loss 0.2437 (0.2600)	Acc@1 93.750 (91.806)	Acc@5 98.438 (99.428)
Epoch: [12][60/150], lr: 0.00100	Time 33.049 (18.912)	Data 29.701 (15.694)	Loss 0.3512 (0.2564)	Acc@1 89.062 (91.650)	Acc@5 100.000 (99.488)
Epoch: [12][80/150], lr: 0.00100	Time 34.632 (18.818)	Data 30.962 (15.608)	Loss 0.2003 (0.2626)	Acc@1 93.750 (91.358)	Acc@5 100.000 (99.479)
Epoch: [12][100/150], lr: 0.00100	Time 33.120 (18.770)	Data 29.858 (15.565)	Loss 0.2544 (0.2677)	Acc@1 89.062 (91.275)	Acc@5 100.000 (99.412)
Epoch: [12][120/150], lr: 0.00100	Time 34.122 (18.753)	Data 30.559 (15.548)	Loss 0.4421 (0.2780)	Acc@1 84.375 (90.999)	Acc@5 98.438 (99.354)
Epoch: [12][140/150], lr: 0.00100	Time 35.063 (18.758)	Data 31.871 (15.546)	Loss 0.4401 (0.2780)	Acc@1 84.375 (90.957)	Acc@5 98.438 (99.368)
Epoch: [13][0/150], lr: 0.00100	Time 45.788 (45.788)	Data 42.497 (42.497)	Loss 0.2862 (0.2862)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [13][20/150], lr: 0.00100	Time 33.327 (19.472)	Data 30.288 (16.338)	Loss 0.2504 (0.2480)	Acc@1 92.188 (92.113)	Acc@5 100.000 (99.405)
Epoch: [13][40/150], lr: 0.00100	Time 33.340 (18.895)	Data 30.199 (15.778)	Loss 0.2233 (0.2648)	Acc@1 95.312 (91.311)	Acc@5 98.438 (99.390)
Epoch: [13][60/150], lr: 0.00100	Time 34.250 (18.767)	Data 31.098 (15.628)	Loss 0.2499 (0.2828)	Acc@1 90.625 (90.856)	Acc@5 100.000 (99.360)
Epoch: [13][80/150], lr: 0.00100	Time 34.583 (18.772)	Data 31.174 (15.616)	Loss 0.2780 (0.2761)	Acc@1 89.062 (91.049)	Acc@5 100.000 (99.460)
Epoch: [13][100/150], lr: 0.00100	Time 34.160 (18.812)	Data 31.190 (15.657)	Loss 0.1877 (0.2686)	Acc@1 93.750 (91.383)	Acc@5 98.438 (99.381)
Epoch: [13][120/150], lr: 0.00100	Time 34.239 (18.817)	Data 31.149 (15.646)	Loss 0.1705 (0.2595)	Acc@1 95.312 (91.761)	Acc@5 100.000 (99.393)
Epoch: [13][140/150], lr: 0.00100	Time 34.783 (18.810)	Data 31.504 (15.632)	Loss 0.2253 (0.2631)	Acc@1 90.625 (91.744)	Acc@5 100.000 (99.346)
Epoch: [14][0/150], lr: 0.00100	Time 45.229 (45.229)	Data 41.620 (41.620)	Loss 0.2420 (0.2420)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [14][20/150], lr: 0.00100	Time 33.556 (19.591)	Data 30.260 (16.438)	Loss 0.2447 (0.2575)	Acc@1 92.188 (91.667)	Acc@5 98.438 (99.107)
Epoch: [14][40/150], lr: 0.00100	Time 34.386 (19.128)	Data 31.063 (15.993)	Loss 0.1667 (0.2313)	Acc@1 93.750 (92.264)	Acc@5 100.000 (99.390)
Epoch: [14][60/150], lr: 0.00100	Time 35.060 (18.906)	Data 31.898 (15.769)	Loss 0.3646 (0.2385)	Acc@1 89.062 (92.085)	Acc@5 98.438 (99.360)
Epoch: [14][80/150], lr: 0.00100	Time 34.322 (18.783)	Data 31.203 (15.655)	Loss 0.3160 (0.2438)	Acc@1 90.625 (91.937)	Acc@5 98.438 (99.325)
Epoch: [14][100/150], lr: 0.00100	Time 34.108 (18.742)	Data 30.830 (15.614)	Loss 0.3312 (0.2495)	Acc@1 87.500 (91.940)	Acc@5 100.000 (99.304)
Epoch: [14][120/150], lr: 0.00100	Time 33.491 (18.692)	Data 30.288 (15.567)	Loss 0.1117 (0.2486)	Acc@1 96.875 (91.994)	Acc@5 100.000 (99.329)
Epoch: [14][140/150], lr: 0.00100	Time 34.817 (18.676)	Data 31.684 (15.549)	Loss 0.1334 (0.2501)	Acc@1 96.875 (92.088)	Acc@5 100.000 (99.280)
Test: [0/60]	Time 42.692 (42.692)	Loss 1.7325 (1.7325)	Acc@1 54.688 (54.688)	Acc@5 92.188 (92.188)
Test: [20/60]	Time 34.406 (19.052)	Loss 5.5305 (1.4690)	Acc@1 37.500 (69.271)	Acc@5 56.250 (89.137)
Test: [40/60]	Time 34.319 (18.508)	Loss 0.8575 (1.2751)	Acc@1 79.688 (71.989)	Acc@5 90.625 (90.625)
 * Acc@1 73.249 Acc@5 91.330 Loss 1.20679
Epoch: [15][0/150], lr: 0.00100	Time 43.290 (43.290)	Data 39.941 (39.941)	Loss 0.2008 (0.2008)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)
Epoch: [15][20/150], lr: 0.00100	Time 35.280 (20.599)	Data 31.257 (17.492)	Loss 0.4176 (0.3227)	Acc@1 89.062 (90.327)	Acc@5 96.875 (98.586)
Epoch: [15][40/150], lr: 0.00100	Time 34.450 (20.086)	Data 31.176 (16.963)	Loss 0.1937 (0.3135)	Acc@1 95.312 (90.549)	Acc@5 100.000 (98.933)
Epoch: [15][60/150], lr: 0.00100	Time 34.792 (19.820)	Data 31.556 (16.698)	Loss 0.1640 (0.2818)	Acc@1 93.750 (91.598)	Acc@5 100.000 (99.103)
Traceback (most recent call last):
  File "main.py", line 391, in <module>
    main()
  File "main.py", line 144, in main
    train(train_loader, model, criterion, optimizer, epoch)
  File "main.py", line 194, in train
    for i, (input, target) in enumerate(train_loader):
  File "/home/alex039u2/data/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 623, in __next__
    return self._process_next_batch(batch)
  File "/home/alex039u2/data/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 658, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
FileNotFoundError: Traceback (most recent call last):
  File "/home/alex039u2/data/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/alex039u2/data/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 138, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/lfs01/workdirs/alex039/alex039u2/tsn_paper/server_scripts/real-time-action-recognition/UCF_Dataset.py", line 137, in __getitem__
    return self.Vid2Frames(vid_info, indices)
  File "/lfs01/workdirs/alex039/alex039u2/tsn_paper/server_scripts/real-time-action-recognition/UCF_Dataset.py", line 116, in Vid2Frames
    seg_imgs = [Image.open(os.path.join(info.path, self.image_prefix.format(p))).convert('RGB')]
  File "/home/alex039u2/data/anaconda3/lib/python3.7/site-packages/PIL/Image.py", line 2580, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/home/alex039u2/data/tsn_paper/datasets/jpegs_256/v_LongJump_g18_c03/frame000110.jpg'

End of Training .................................

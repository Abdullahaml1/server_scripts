Start Training ...................................

          Initializing TSN with base model: BNInception.
          TSN Configurations:
              input_modality:     RGBDiff
              num_segments:       3
              new_length:         5
              consensus_module:   avg
              dropout_ratio:      0.8
               
Load and modify the standard model FC output layer
Dropout Layer added and The modified linear layer is : Linear(in_features=1024, out_features=101, bias=True)
Done. Loading and Modifying 
 ---------------------------------------------------
Converting the ImageNet model to RGBDiff model
The modified 1st layer is Conv2d(15, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
Done. RGBDiff model is ready.
Loading checkpoint '/home/alex039u2/data/tsn_paper/server_scripts/real-time-action-recognition/_rgbdiff_checkpoint.pth.tar'
Loaded checkpoint 'False' epoch 90
---------------------------------------------------
group: first_conv_weight has 1 params, lr_mult: 1, decay_mult: 1
group: first_conv_bias has 1 params, lr_mult: 2, decay_mult: 0
group: normal_weight has 69 params, lr_mult: 1, decay_mult: 1
group: normal_bias has 69 params, lr_mult: 2, decay_mult: 0
group: BN scale/shift has 2 params, lr_mult: 1, decay_mult: 0
---------------------------------------------------
Epoch: [90][0/150], lr: 0.00010	Time 47.670 (47.670)	Data 26.915 (26.915)	Loss 0.0836 (0.0836)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [90][20/150], lr: 0.00010	Time 1.737 (3.593)	Data 0.000 (1.283)	Loss 0.0651 (0.0535)	Acc@1 98.438 (98.512)	Acc@5 100.000 (100.000)
Epoch: [90][40/150], lr: 0.00010	Time 1.331 (2.511)	Data 0.000 (0.667)	Loss 0.0157 (0.0468)	Acc@1 100.000 (98.628)	Acc@5 100.000 (100.000)
Epoch: [90][60/150], lr: 0.00010	Time 1.334 (2.358)	Data 0.000 (0.634)	Loss 0.0012 (0.0461)	Acc@1 100.000 (98.540)	Acc@5 100.000 (100.000)
Epoch: [90][80/150], lr: 0.00010	Time 1.331 (2.306)	Data 0.000 (0.634)	Loss 0.0069 (0.0436)	Acc@1 100.000 (98.630)	Acc@5 100.000 (100.000)
Epoch: [90][100/150], lr: 0.00010	Time 1.330 (2.246)	Data 0.000 (0.627)	Loss 0.0092 (0.0449)	Acc@1 100.000 (98.623)	Acc@5 100.000 (99.985)
Epoch: [90][120/150], lr: 0.00010	Time 1.326 (2.225)	Data 0.000 (0.625)	Loss 0.0058 (0.0456)	Acc@1 100.000 (98.605)	Acc@5 100.000 (99.974)
Epoch: [90][140/150], lr: 0.00010	Time 1.331 (2.211)	Data 0.000 (0.625)	Loss 0.1041 (0.0450)	Acc@1 95.312 (98.648)	Acc@5 100.000 (99.967)
Epoch: [91][0/150], lr: 0.00010	Time 32.153 (32.153)	Data 28.231 (28.231)	Loss 0.0054 (0.0054)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [91][20/150], lr: 0.00010	Time 7.680 (3.471)	Data 6.223 (1.895)	Loss 0.0126 (0.0544)	Acc@1 100.000 (98.065)	Acc@5 100.000 (99.926)
Epoch: [91][40/150], lr: 0.00010	Time 8.394 (2.796)	Data 6.267 (1.264)	Loss 0.0059 (0.0498)	Acc@1 100.000 (98.361)	Acc@5 100.000 (99.962)
Epoch: [91][60/150], lr: 0.00010	Time 7.349 (2.542)	Data 5.272 (1.032)	Loss 0.0683 (0.0468)	Acc@1 98.438 (98.514)	Acc@5 100.000 (99.949)
Epoch: [91][80/150], lr: 0.00010	Time 7.487 (2.421)	Data 5.811 (0.922)	Loss 0.0073 (0.0454)	Acc@1 100.000 (98.534)	Acc@5 100.000 (99.942)
Epoch: [91][100/150], lr: 0.00010	Time 8.040 (2.368)	Data 6.355 (0.866)	Loss 0.0515 (0.0453)	Acc@1 98.438 (98.530)	Acc@5 100.000 (99.954)
Epoch: [91][120/150], lr: 0.00010	Time 8.582 (2.327)	Data 5.986 (0.828)	Loss 0.0994 (0.0452)	Acc@1 96.875 (98.541)	Acc@5 100.000 (99.948)
Epoch: [91][140/150], lr: 0.00010	Time 6.964 (2.277)	Data 5.559 (0.786)	Loss 0.0489 (0.0432)	Acc@1 98.438 (98.615)	Acc@5 100.000 (99.945)
Epoch: [92][0/150], lr: 0.00010	Time 33.846 (33.846)	Data 30.130 (30.130)	Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [92][20/150], lr: 0.00010	Time 10.325 (3.634)	Data 8.409 (2.083)	Loss 0.0069 (0.0433)	Acc@1 100.000 (98.586)	Acc@5 100.000 (100.000)
Epoch: [92][40/150], lr: 0.00010	Time 7.054 (2.852)	Data 5.224 (1.329)	Loss 0.0275 (0.0415)	Acc@1 100.000 (98.742)	Acc@5 100.000 (99.962)
Epoch: [92][60/150], lr: 0.00010	Time 7.187 (2.574)	Data 4.539 (1.066)	Loss 0.0268 (0.0444)	Acc@1 98.438 (98.642)	Acc@5 100.000 (99.949)
Epoch: [92][80/150], lr: 0.00010	Time 9.030 (2.465)	Data 6.944 (0.971)	Loss 0.0040 (0.0422)	Acc@1 100.000 (98.650)	Acc@5 100.000 (99.942)
Epoch: [92][100/150], lr: 0.00010	Time 6.717 (2.358)	Data 5.310 (0.869)	Loss 0.0168 (0.0437)	Acc@1 100.000 (98.623)	Acc@5 100.000 (99.954)
Epoch: [92][120/150], lr: 0.00010	Time 7.865 (2.338)	Data 5.779 (0.825)	Loss 0.0350 (0.0420)	Acc@1 98.438 (98.631)	Acc@5 100.000 (99.948)
Epoch: [92][140/150], lr: 0.00010	Time 6.240 (2.298)	Data 4.724 (0.792)	Loss 0.0553 (0.0417)	Acc@1 96.875 (98.670)	Acc@5 100.000 (99.956)
Epoch: [93][0/150], lr: 0.00010	Time 33.746 (33.746)	Data 30.166 (30.166)	Loss 0.0381 (0.0381)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [93][20/150], lr: 0.00010	Time 7.063 (3.289)	Data 5.553 (1.730)	Loss 0.0921 (0.0483)	Acc@1 96.875 (98.363)	Acc@5 100.000 (99.926)
Epoch: [93][40/150], lr: 0.00010	Time 7.062 (2.687)	Data 5.640 (1.148)	Loss 0.0082 (0.0432)	Acc@1 100.000 (98.628)	Acc@5 100.000 (99.848)
Epoch: [93][60/150], lr: 0.00010	Time 7.482 (2.490)	Data 5.564 (0.968)	Loss 0.0365 (0.0400)	Acc@1 98.438 (98.796)	Acc@5 100.000 (99.898)
Epoch: [93][80/150], lr: 0.00010	Time 7.203 (2.360)	Data 5.527 (0.854)	Loss 0.0409 (0.0416)	Acc@1 96.875 (98.650)	Acc@5 100.000 (99.904)
Epoch: [93][100/150], lr: 0.00010	Time 6.043 (2.306)	Data 4.659 (0.794)	Loss 0.0091 (0.0421)	Acc@1 100.000 (98.716)	Acc@5 100.000 (99.907)
Epoch: [93][120/150], lr: 0.00010	Time 3.780 (2.264)	Data 2.378 (0.751)	Loss 0.0503 (0.0415)	Acc@1 98.438 (98.709)	Acc@5 100.000 (99.910)
Epoch: [93][140/150], lr: 0.00010	Time 7.460 (2.239)	Data 5.805 (0.732)	Loss 0.0547 (0.0403)	Acc@1 98.438 (98.770)	Acc@5 100.000 (99.922)
Epoch: [94][0/150], lr: 0.00010	Time 33.852 (33.852)	Data 29.346 (29.346)	Loss 0.0357 (0.0357)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [94][20/150], lr: 0.00010	Time 5.320 (3.315)	Data 2.595 (1.746)	Loss 0.0083 (0.0431)	Acc@1 100.000 (98.363)	Acc@5 100.000 (99.851)
Epoch: [94][40/150], lr: 0.00010	Time 4.992 (2.652)	Data 3.579 (1.135)	Loss 0.0180 (0.0441)	Acc@1 100.000 (98.361)	Acc@5 100.000 (99.886)
Epoch: [94][60/150], lr: 0.00010	Time 6.764 (2.490)	Data 4.419 (0.969)	Loss 0.0374 (0.0397)	Acc@1 98.438 (98.591)	Acc@5 100.000 (99.923)
Epoch: [94][80/150], lr: 0.00010	Time 6.477 (2.375)	Data 4.879 (0.887)	Loss 0.0110 (0.0407)	Acc@1 100.000 (98.669)	Acc@5 100.000 (99.865)
Epoch: [94][100/150], lr: 0.00010	Time 9.664 (2.351)	Data 8.228 (0.862)	Loss 0.0176 (0.0386)	Acc@1 100.000 (98.762)	Acc@5 100.000 (99.892)
Epoch: [94][120/150], lr: 0.00010	Time 6.698 (2.307)	Data 5.304 (0.822)	Loss 0.0454 (0.0386)	Acc@1 98.438 (98.799)	Acc@5 100.000 (99.897)
Epoch: [94][140/150], lr: 0.00010	Time 6.800 (2.268)	Data 5.216 (0.781)	Loss 0.0193 (0.0366)	Acc@1 98.438 (98.881)	Acc@5 100.000 (99.911)
Test: [0/60]	Time 27.612 (27.612)	Loss 0.0317 (0.0317)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Test: [20/60]	Time 14.408 (3.093)	Loss 2.7003 (1.3282)	Acc@1 57.812 (75.223)	Acc@5 78.125 (92.262)
Test: [40/60]	Time 14.882 (2.618)	Loss 0.8793 (1.3421)	Acc@1 81.250 (75.267)	Acc@5 93.750 (91.921)
 * Acc@1 75.628 Acc@5 92.281 Loss 1.28553
slurmstepd: error: *** JOB 223882 ON comp004 CANCELLED AT 2019-02-23T21:03:41 ***
